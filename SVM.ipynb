{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "  gender   age  samerace  importance_same_race  importance_same_religion  \\\n0      1  21.0         0                   2.0                       4.0   \n1      1  21.0         0                   2.0                       4.0   \n2      1  21.0         0                   2.0                       4.0   \n3      1  21.0         0                   2.0                       4.0   \n4      1  21.0         0                   2.0                       4.0   \n\n   attractive_important  sincere_important  intellicence_important  \\\n0                  15.0               20.0                    20.0   \n1                  15.0               20.0                    20.0   \n2                  15.0               20.0                    20.0   \n3                  15.0               20.0                    20.0   \n4                  15.0               20.0                    20.0   \n\n   funny_important  ambtition_important  ...   tv  theater  movies  concerts  \\\n0             15.0                 15.0  ...  9.0      1.0    10.0      10.0   \n1             15.0                 15.0  ...  9.0      1.0    10.0      10.0   \n2             15.0                 15.0  ...  9.0      1.0    10.0      10.0   \n3             15.0                 15.0  ...  9.0      1.0    10.0      10.0   \n4             15.0                 15.0  ...  9.0      1.0    10.0      10.0   \n\n   music  shopping  yoga  expected_happy_with_sd_people  like  match  \n0    9.0       8.0   1.0                            3.0   7.0      0  \n1    9.0       8.0   1.0                            3.0   7.0      0  \n2    9.0       8.0   1.0                            3.0   7.0      1  \n3    9.0       8.0   1.0                            3.0   6.0      1  \n4    9.0       8.0   1.0                            3.0   6.0      0  \n\n[5 rows x 40 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>gender</th>\n      <th>age</th>\n      <th>samerace</th>\n      <th>importance_same_race</th>\n      <th>importance_same_religion</th>\n      <th>attractive_important</th>\n      <th>sincere_important</th>\n      <th>intellicence_important</th>\n      <th>funny_important</th>\n      <th>ambtition_important</th>\n      <th>...</th>\n      <th>tv</th>\n      <th>theater</th>\n      <th>movies</th>\n      <th>concerts</th>\n      <th>music</th>\n      <th>shopping</th>\n      <th>yoga</th>\n      <th>expected_happy_with_sd_people</th>\n      <th>like</th>\n      <th>match</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>21.0</td>\n      <td>0</td>\n      <td>2.0</td>\n      <td>4.0</td>\n      <td>15.0</td>\n      <td>20.0</td>\n      <td>20.0</td>\n      <td>15.0</td>\n      <td>15.0</td>\n      <td>...</td>\n      <td>9.0</td>\n      <td>1.0</td>\n      <td>10.0</td>\n      <td>10.0</td>\n      <td>9.0</td>\n      <td>8.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>7.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>21.0</td>\n      <td>0</td>\n      <td>2.0</td>\n      <td>4.0</td>\n      <td>15.0</td>\n      <td>20.0</td>\n      <td>20.0</td>\n      <td>15.0</td>\n      <td>15.0</td>\n      <td>...</td>\n      <td>9.0</td>\n      <td>1.0</td>\n      <td>10.0</td>\n      <td>10.0</td>\n      <td>9.0</td>\n      <td>8.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>7.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>21.0</td>\n      <td>0</td>\n      <td>2.0</td>\n      <td>4.0</td>\n      <td>15.0</td>\n      <td>20.0</td>\n      <td>20.0</td>\n      <td>15.0</td>\n      <td>15.0</td>\n      <td>...</td>\n      <td>9.0</td>\n      <td>1.0</td>\n      <td>10.0</td>\n      <td>10.0</td>\n      <td>9.0</td>\n      <td>8.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>7.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>21.0</td>\n      <td>0</td>\n      <td>2.0</td>\n      <td>4.0</td>\n      <td>15.0</td>\n      <td>20.0</td>\n      <td>20.0</td>\n      <td>15.0</td>\n      <td>15.0</td>\n      <td>...</td>\n      <td>9.0</td>\n      <td>1.0</td>\n      <td>10.0</td>\n      <td>10.0</td>\n      <td>9.0</td>\n      <td>8.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>6.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>21.0</td>\n      <td>0</td>\n      <td>2.0</td>\n      <td>4.0</td>\n      <td>15.0</td>\n      <td>20.0</td>\n      <td>20.0</td>\n      <td>15.0</td>\n      <td>15.0</td>\n      <td>...</td>\n      <td>9.0</td>\n      <td>1.0</td>\n      <td>10.0</td>\n      <td>10.0</td>\n      <td>9.0</td>\n      <td>8.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>6.0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 40 columns</p>\n</div>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"Speeddating_Processed.csv\")\n",
    "df = df.drop([\"Unnamed: 0\", \"has_null\", \"wave\", \"interests_correlate\", \"guess_prob_liked\", \"decision\", \"decision_o\", \"met\"], axis=1)\n",
    "df = df.drop([col for col in df if col.startswith(\"d_\")], axis=1)\n",
    "df = df.drop([col for col in df if \"_o\" in col], axis=1)\n",
    "\n",
    "for ind, row in df.iterrows():\n",
    "    if row[\"gender\"] == \"female\":\n",
    "        df.loc[ind, \"gender\"] = 1\n",
    "    elif row[\"gender\"] == \"male\":\n",
    "        df.loc[ind, \"gender\"] = 0\n",
    "\n",
    "# df = df.join(pd.get_dummies(df.pop(\"race\"), dtype=int))\n",
    "df = df.drop(\"race\", axis=1)\n",
    "\n",
    "# Field Column One Hot Encoded or Dropped\n",
    "# df = df.join(pd.get_dummies(df.pop(\"field\"), dtype=int))\n",
    "df = df.drop(\"field\", axis=1)\n",
    "\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "           age  importance_same_race  importance_same_religion  \\\n0    -1.510659             -0.629416                  0.121457   \n1    -1.510659             -0.629416                  0.121457   \n2    -1.510659             -0.629416                  0.121457   \n3    -1.510659             -0.629416                  0.121457   \n4    -1.510659             -0.629416                  0.121457   \n...        ...                   ...                       ...   \n7074 -0.371125             -0.982478                 -0.943086   \n7075 -0.371125             -0.982478                 -0.943086   \n7076 -0.371125             -0.982478                 -0.943086   \n7077 -0.371125             -0.982478                 -0.943086   \n7078 -0.371125             -0.982478                 -0.943086   \n\n      attractive_important  sincere_important  intellicence_important  \\\n0                -0.597422           0.362857               -0.057670   \n1                -0.597422           0.362857               -0.057670   \n2                -0.597422           0.362857               -0.057670   \n3                -0.597422           0.362857               -0.057670   \n4                -0.597422           0.362857               -0.057670   \n...                    ...                ...                     ...   \n7074              4.046668          -2.518729               -0.797401   \n7075              4.046668          -2.518729               -0.797401   \n7076              4.046668          -2.518729               -0.797401   \n7077              4.046668          -2.518729               -0.797401   \n7078              4.046668          -2.518729               -0.797401   \n\n      funny_important  ambtition_important  shared_interests_important  \\\n0           -0.411495             0.700629                    0.493945   \n1           -0.411495             0.700629                    0.493945   \n2           -0.411495             0.700629                    0.493945   \n3           -0.411495             0.700629                    0.493945   \n4           -0.411495             0.700629                    0.493945   \n...               ...                  ...                         ...   \n7074        -0.411495            -1.767049                   -1.873438   \n7075        -0.411495            -1.767049                   -1.873438   \n7076        -0.411495            -1.767049                   -1.873438   \n7077        -0.411495            -1.767049                   -1.873438   \n7078        -0.411495            -1.767049                   -1.873438   \n\n      attractive  ...    movies  concerts     music  shopping      yoga  \\\n0      -0.787565  ...  1.235556  1.477397  0.651220  0.880210 -1.244794   \n1      -0.787565  ...  1.235556  1.477397  0.651220  0.880210 -1.244794   \n2      -0.787565  ...  1.235556  1.477397  0.651220  0.880210 -1.244794   \n3      -0.787565  ...  1.235556  1.477397  0.651220  0.880210 -1.244794   \n4      -0.787565  ...  1.235556  1.477397  0.651220  0.880210 -1.244794   \n...          ...  ...       ...       ...       ...       ...       ...   \n7074    0.652676  ...  0.627569  1.477397  1.222117  0.496882 -0.506253   \n7075    0.652676  ...  0.627569  1.477397  1.222117  0.496882 -0.506253   \n7076    0.652676  ...  0.627569  1.477397  1.222117  0.496882 -0.506253   \n7077    0.652676  ...  0.627569  1.477397  1.222117  0.496882 -0.506253   \n7078    0.652676  ...  0.627569  1.477397  1.222117  0.496882 -0.506253   \n\n      expected_happy_with_sd_people      like  match  gender  samerace  \n0                         -1.455416  0.465329      0       1         0  \n1                         -1.455416  0.465329      0       1         0  \n2                         -1.455416  0.465329      1       1         0  \n3                         -1.455416 -0.086090      1       1         0  \n4                         -1.455416 -0.086090      0       1         0  \n...                             ...       ...    ...     ...       ...  \n7074                       2.591509 -1.188927      0       0         1  \n7075                       2.591509 -2.291764      0       0         0  \n7076                       2.591509 -1.188927      0       0         0  \n7077                       2.591509 -0.637508      0       0         0  \n7078                       2.591509 -1.188927      0       0         0  \n\n[7079 rows x 40 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>importance_same_race</th>\n      <th>importance_same_religion</th>\n      <th>attractive_important</th>\n      <th>sincere_important</th>\n      <th>intellicence_important</th>\n      <th>funny_important</th>\n      <th>ambtition_important</th>\n      <th>shared_interests_important</th>\n      <th>attractive</th>\n      <th>...</th>\n      <th>movies</th>\n      <th>concerts</th>\n      <th>music</th>\n      <th>shopping</th>\n      <th>yoga</th>\n      <th>expected_happy_with_sd_people</th>\n      <th>like</th>\n      <th>match</th>\n      <th>gender</th>\n      <th>samerace</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-1.510659</td>\n      <td>-0.629416</td>\n      <td>0.121457</td>\n      <td>-0.597422</td>\n      <td>0.362857</td>\n      <td>-0.057670</td>\n      <td>-0.411495</td>\n      <td>0.700629</td>\n      <td>0.493945</td>\n      <td>-0.787565</td>\n      <td>...</td>\n      <td>1.235556</td>\n      <td>1.477397</td>\n      <td>0.651220</td>\n      <td>0.880210</td>\n      <td>-1.244794</td>\n      <td>-1.455416</td>\n      <td>0.465329</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-1.510659</td>\n      <td>-0.629416</td>\n      <td>0.121457</td>\n      <td>-0.597422</td>\n      <td>0.362857</td>\n      <td>-0.057670</td>\n      <td>-0.411495</td>\n      <td>0.700629</td>\n      <td>0.493945</td>\n      <td>-0.787565</td>\n      <td>...</td>\n      <td>1.235556</td>\n      <td>1.477397</td>\n      <td>0.651220</td>\n      <td>0.880210</td>\n      <td>-1.244794</td>\n      <td>-1.455416</td>\n      <td>0.465329</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-1.510659</td>\n      <td>-0.629416</td>\n      <td>0.121457</td>\n      <td>-0.597422</td>\n      <td>0.362857</td>\n      <td>-0.057670</td>\n      <td>-0.411495</td>\n      <td>0.700629</td>\n      <td>0.493945</td>\n      <td>-0.787565</td>\n      <td>...</td>\n      <td>1.235556</td>\n      <td>1.477397</td>\n      <td>0.651220</td>\n      <td>0.880210</td>\n      <td>-1.244794</td>\n      <td>-1.455416</td>\n      <td>0.465329</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-1.510659</td>\n      <td>-0.629416</td>\n      <td>0.121457</td>\n      <td>-0.597422</td>\n      <td>0.362857</td>\n      <td>-0.057670</td>\n      <td>-0.411495</td>\n      <td>0.700629</td>\n      <td>0.493945</td>\n      <td>-0.787565</td>\n      <td>...</td>\n      <td>1.235556</td>\n      <td>1.477397</td>\n      <td>0.651220</td>\n      <td>0.880210</td>\n      <td>-1.244794</td>\n      <td>-1.455416</td>\n      <td>-0.086090</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-1.510659</td>\n      <td>-0.629416</td>\n      <td>0.121457</td>\n      <td>-0.597422</td>\n      <td>0.362857</td>\n      <td>-0.057670</td>\n      <td>-0.411495</td>\n      <td>0.700629</td>\n      <td>0.493945</td>\n      <td>-0.787565</td>\n      <td>...</td>\n      <td>1.235556</td>\n      <td>1.477397</td>\n      <td>0.651220</td>\n      <td>0.880210</td>\n      <td>-1.244794</td>\n      <td>-1.455416</td>\n      <td>-0.086090</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>7074</th>\n      <td>-0.371125</td>\n      <td>-0.982478</td>\n      <td>-0.943086</td>\n      <td>4.046668</td>\n      <td>-2.518729</td>\n      <td>-0.797401</td>\n      <td>-0.411495</td>\n      <td>-1.767049</td>\n      <td>-1.873438</td>\n      <td>0.652676</td>\n      <td>...</td>\n      <td>0.627569</td>\n      <td>1.477397</td>\n      <td>1.222117</td>\n      <td>0.496882</td>\n      <td>-0.506253</td>\n      <td>2.591509</td>\n      <td>-1.188927</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7075</th>\n      <td>-0.371125</td>\n      <td>-0.982478</td>\n      <td>-0.943086</td>\n      <td>4.046668</td>\n      <td>-2.518729</td>\n      <td>-0.797401</td>\n      <td>-0.411495</td>\n      <td>-1.767049</td>\n      <td>-1.873438</td>\n      <td>0.652676</td>\n      <td>...</td>\n      <td>0.627569</td>\n      <td>1.477397</td>\n      <td>1.222117</td>\n      <td>0.496882</td>\n      <td>-0.506253</td>\n      <td>2.591509</td>\n      <td>-2.291764</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7076</th>\n      <td>-0.371125</td>\n      <td>-0.982478</td>\n      <td>-0.943086</td>\n      <td>4.046668</td>\n      <td>-2.518729</td>\n      <td>-0.797401</td>\n      <td>-0.411495</td>\n      <td>-1.767049</td>\n      <td>-1.873438</td>\n      <td>0.652676</td>\n      <td>...</td>\n      <td>0.627569</td>\n      <td>1.477397</td>\n      <td>1.222117</td>\n      <td>0.496882</td>\n      <td>-0.506253</td>\n      <td>2.591509</td>\n      <td>-1.188927</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7077</th>\n      <td>-0.371125</td>\n      <td>-0.982478</td>\n      <td>-0.943086</td>\n      <td>4.046668</td>\n      <td>-2.518729</td>\n      <td>-0.797401</td>\n      <td>-0.411495</td>\n      <td>-1.767049</td>\n      <td>-1.873438</td>\n      <td>0.652676</td>\n      <td>...</td>\n      <td>0.627569</td>\n      <td>1.477397</td>\n      <td>1.222117</td>\n      <td>0.496882</td>\n      <td>-0.506253</td>\n      <td>2.591509</td>\n      <td>-0.637508</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7078</th>\n      <td>-0.371125</td>\n      <td>-0.982478</td>\n      <td>-0.943086</td>\n      <td>4.046668</td>\n      <td>-2.518729</td>\n      <td>-0.797401</td>\n      <td>-0.411495</td>\n      <td>-1.767049</td>\n      <td>-1.873438</td>\n      <td>0.652676</td>\n      <td>...</td>\n      <td>0.627569</td>\n      <td>1.477397</td>\n      <td>1.222117</td>\n      <td>0.496882</td>\n      <td>-0.506253</td>\n      <td>2.591509</td>\n      <td>-1.188927</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>7079 rows Ã— 40 columns</p>\n</div>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Withhold Binary columns from regularization\n",
    "tempDF = df.drop([\"match\", \"gender\", \"samerace\"], axis=1)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled_arr = scaler.fit_transform(tempDF)\n",
    "scaled_df = pd.DataFrame(scaled_arr, index=tempDF.index, columns=tempDF.columns).join(df.loc[:,[\"match\", \"gender\", \"samerace\"]])\n",
    "\n",
    "scaled_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "X = scaled_df.drop(\"match\", axis=1)\n",
    "y = scaled_df[\"match\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "GridSearchCV(estimator=SVC(),\n             param_grid={'C': [1, 10],\n                         'kernel': ('linear', 'poly', 'rbf', 'sigmoid')})"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = svm.SVC()\n",
    "\n",
    "parameters = {'kernel':('linear', 'poly', 'rbf', 'sigmoid'), 'C':[1, 10]}\n",
    "CVmodel = GridSearchCV(model, parameters)\n",
    "\n",
    "CVmodel.fit(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "data": {
      "text/plain": "{'C': 10, 'kernel': 'rbf'}"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CVmodel.best_params_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "(0.8350282485875706, 0.4065040650406504, 0.31746031746031744)"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = CVmodel.predict(X_test)\n",
    "acc = accuracy_score(y_test, preds)\n",
    "f1 = f1_score(y_test, preds)\n",
    "rec = recall_score(y_test, preds)\n",
    "\n",
    "acc, f1, rec"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}